{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE/Y+/zHsBaoUHW0ZDoYng",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kathy42xu/Blockhouse_quant_assessment/blob/main/Auto2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA1E301sVvF4",
        "outputId": "9c12fcb2-988c-49af-afb4-91f24b9fe30e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-17 15:20:06--  https://files.grouplens.org/datasets/movielens/ml-32m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 238950008 (228M) [application/zip]\n",
            "Saving to: ‘movielens/ml-32m.zip’\n",
            "\n",
            "movielens/ml-32m.zi 100%[===================>] 227.88M  16.6MB/s    in 15s     \n",
            "\n",
            "2025-01-17 15:20:22 (15.2 MB/s) - ‘movielens/ml-32m.zip’ saved [238950008/238950008]\n",
            "\n",
            "Archive:  movielens/ml-32m.zip\n",
            "   creating: movielens/ml-32m/\n",
            "  inflating: movielens/ml-32m/tags.csv  \n",
            "  inflating: movielens/ml-32m/links.csv  \n",
            "  inflating: movielens/ml-32m/README.txt  \n",
            "  inflating: movielens/ml-32m/checksums.txt  \n",
            "  inflating: movielens/ml-32m/ratings.csv  \n",
            "  inflating: movielens/ml-32m/movies.csv  \n",
            "Ratings Data:\n",
            "   userId  movieId  rating  timestamp\n",
            "0       1       17     4.0  944249077\n",
            "1       1       25     1.0  944250228\n",
            "2       1       29     2.0  943230976\n",
            "3       1       30     5.0  944249077\n",
            "4       1       32     5.0  943228858\n",
            "\n",
            "Movies Data:\n",
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1                   Adventure|Children|Fantasy  \n",
            "2                               Comedy|Romance  \n",
            "3                         Comedy|Drama|Romance  \n",
            "4                                       Comedy  \n",
            "\n",
            "Tags Data:\n",
            "   userId  movieId          tag   timestamp\n",
            "0      22    26479  Kevin Kline  1583038886\n",
            "1      22    79592     misogyny  1581476297\n",
            "2      22   247150   acrophobia  1622483469\n",
            "3      34     2174        music  1249808064\n",
            "4      34     2174        weird  1249808102\n",
            "\n",
            "Links Data:\n",
            "   movieId  imdbId   tmdbId\n",
            "0        1  114709    862.0\n",
            "1        2  113497   8844.0\n",
            "2        3  113228  15602.0\n",
            "3        4  114885  31357.0\n",
            "4        5  113041  11862.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('movielens', exist_ok=True)\n",
        "\n",
        "\n",
        "!wget -O movielens/ml-32m.zip https://files.grouplens.org/datasets/movielens/ml-32m.zip\n",
        "\n",
        "!unzip movielens/ml-32m.zip -d movielens/\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the ratings data\n",
        "ratings = pd.read_csv('movielens/ml-32m/ratings.csv')\n",
        "print(\"Ratings Data:\")\n",
        "print(ratings.head())\n",
        "\n",
        "# Load the movies data\n",
        "movies = pd.read_csv('movielens/ml-32m/movies.csv')\n",
        "print(\"\\nMovies Data:\")\n",
        "print(movies.head())\n",
        "\n",
        "# Load the tags data\n",
        "tags = pd.read_csv('movielens/ml-32m/tags.csv')\n",
        "print(\"\\nTags Data:\")\n",
        "print(tags.head())\n",
        "\n",
        "# Load the links data\n",
        "links = pd.read_csv('movielens/ml-32m/links.csv')\n",
        "print(\"\\nLinks Data:\")\n",
        "print(links.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load datasets\n",
        "ratings = pd.read_csv('movielens/ml-32m/ratings.csv')\n",
        "movies = pd.read_csv('movielens/ml-32m/movies.csv')\n",
        "\n",
        "# Merge ratings with movies to filter based on titles\n",
        "merged_data = ratings.merge(movies, on=\"movieId\")\n",
        "all_ratings = merged_data[\n",
        "    merged_data['title'].str.endswith(tuple(f\"({year})\" for year in range(2020, 2025)))\n",
        "]\n",
        "\n",
        "# Display filtered data\n",
        "print(f\"Amount of data after filtering: {len(all_ratings)}\")\n",
        "print(all_ratings.head())\n",
        "\n",
        "# Create user-item interaction matrix\n",
        "user_item_matrix = all_ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_data, test_data = train_test_split(user_item_matrix, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YGq3tjiV4YA",
        "outputId": "f9f33243-6e0a-410b-b676-770d6816c5fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of data after filtering: 273932\n",
            "      userId  movieId  rating   timestamp  \\\n",
            "2237      22   235509     2.5  1611070726   \n",
            "2238      22   247150     3.0  1622483323   \n",
            "2239      22   278420     4.0  1668895485   \n",
            "2240      22   279412     3.5  1668895505   \n",
            "2241      22   280236     4.0  1674334098   \n",
            "\n",
            "                                    title                   genres  \n",
            "2237              Outside the Wire (2021)   Action|Sci-Fi|Thriller  \n",
            "2238                      Stowaway (2021)             Drama|Sci-Fi  \n",
            "2239  Weird: The Al Yankovic Story (2022)             Comedy|Drama  \n",
            "2240                Enola Holmes 2 (2022)  Adventure|Crime|Mystery  \n",
            "2241                      Spirited (2022)                   Comedy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "class AutoRec:\n",
        "    def __init__(self, num_items, hidden_neurons, learning_rate, lambda_value):\n",
        "        self.num_items = num_items\n",
        "        self.hidden_neurons = hidden_neurons\n",
        "        self.learning_rate = learning_rate\n",
        "        self.lambda_value = lambda_value\n",
        "\n",
        "        self.input_R = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, self.num_items])\n",
        "        self.input_mask_R = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, self.num_items])\n",
        "\n",
        "        self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "      with tf.compat.v1.variable_scope(\"AutoRec\", reuse=tf.compat.v1.AUTO_REUSE):\n",
        "        V = tf.compat.v1.get_variable(\"V\", shape=[self.num_items, self.hidden_neurons],\n",
        "                                      initializer=tf.compat.v1.truncated_normal_initializer(mean=0, stddev=0.03))\n",
        "        W = tf.compat.v1.get_variable(\"W\", shape=[self.hidden_neurons, self.num_items],\n",
        "                                      initializer=tf.compat.v1.truncated_normal_initializer(mean=0, stddev=0.03))\n",
        "        mu = tf.compat.v1.get_variable(\"mu\", initializer=tf.zeros(self.hidden_neurons))\n",
        "        b = tf.compat.v1.get_variable(\"b\", initializer=tf.zeros(self.num_items))\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = tf.nn.sigmoid(tf.matmul(self.input_R, V) + mu)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = tf.matmul(self.encoder, W) + b\n",
        "\n",
        "        # Loss\n",
        "        pre_rec_cost = tf.multiply(self.input_R - self.decoder, self.input_mask_R)\n",
        "        rec_cost = tf.reduce_sum(tf.square(pre_rec_cost))\n",
        "        reg_cost = self.lambda_value * 0.5 * (tf.nn.l2_loss(W) + tf.nn.l2_loss(V))\n",
        "\n",
        "        self.loss = rec_cost + reg_cost\n",
        "        self.optimizer = tf.compat.v1.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
        "\n",
        "\n",
        "    def train(self, train_data, mask, epochs, batch_size):\n",
        "        session = tf.compat.v1.Session()\n",
        "        session.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            for i in range(0, len(train_data), batch_size):\n",
        "                batch_data = train_data[i:i + batch_size]\n",
        "                batch_mask = mask[i:i + batch_size]\n",
        "                feed_dict = {self.input_R: batch_data, self.input_mask_R: batch_mask}\n",
        "                _, batch_loss = session.run([self.optimizer, self.loss], feed_dict=feed_dict)\n",
        "                total_loss += batch_loss\n",
        "            print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_data)}\")\n",
        "\n",
        "        self.session = session\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        feed_dict = {self.input_R: test_data}\n",
        "        return self.session.run(self.decoder, feed_dict=feed_dict)\n"
      ],
      "metadata": {
        "id": "KBQrfIHVWKnR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Prepare mask for training\n",
        "train_mask = (train_data > 0).astype(float)\n",
        "\n",
        "# Instantiate and train AutoRec\n",
        "num_items = user_item_matrix.shape[1]\n",
        "hidden_neurons = 500\n",
        "learning_rate = 0.001\n",
        "lambda_value = 0.1\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "autorec = AutoRec(num_items, hidden_neurons, learning_rate, lambda_value)\n",
        "autorec.train(train_data.values, train_mask.values, epochs, batch_size)\n",
        "\n",
        "# Predict on test set\n",
        "test_predictions = autorec.predict(test_data.values)\n",
        "\n",
        "# Evaluate\n",
        "test_mask = (test_data > 0).astype(float)\n",
        "true_ratings = test_data.values[test_mask.values > 0]\n",
        "predicted_ratings = test_predictions[test_mask.values > 0]\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
        "mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
        "\n",
        "print(f\"RMSE: {rmse}, MAE: {mae}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unEnMfGHWSGQ",
        "outputId": "cf73279e-c539-4624-9b5d-6f6d84bec9e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 26.37155637925129\n",
            "Epoch 2, Loss: 12.805680086105973\n",
            "Epoch 3, Loss: 10.999481268365091\n",
            "Epoch 4, Loss: 9.683601651131806\n",
            "Epoch 5, Loss: 8.609995806036551\n",
            "Epoch 6, Loss: 7.521076610986626\n",
            "Epoch 7, Loss: 6.739737504875856\n",
            "Epoch 8, Loss: 5.9795762264517025\n",
            "Epoch 9, Loss: 5.338915321558594\n",
            "Epoch 10, Loss: 4.831098768226595\n",
            "Epoch 11, Loss: 4.455601313126209\n",
            "Epoch 12, Loss: 4.113117302503167\n",
            "Epoch 13, Loss: 3.8243950294284157\n",
            "Epoch 14, Loss: 3.5014272708840943\n",
            "Epoch 15, Loss: 3.2458047420925125\n",
            "Epoch 16, Loss: 3.048075142000611\n",
            "Epoch 17, Loss: 2.926522169840674\n",
            "Epoch 18, Loss: 2.764923915855626\n",
            "Epoch 19, Loss: 2.6715614092564617\n",
            "Epoch 20, Loss: 2.563806288508828\n",
            "Epoch 21, Loss: 2.4992395071704805\n",
            "Epoch 22, Loss: 2.45005186091061\n",
            "Epoch 23, Loss: 2.4266133727750665\n",
            "Epoch 24, Loss: 2.4261550676049137\n",
            "Epoch 25, Loss: 2.4270615782118297\n",
            "Epoch 26, Loss: 2.4655262542317495\n",
            "Epoch 27, Loss: 2.4852877210388065\n",
            "Epoch 28, Loss: 2.4683436579136724\n",
            "Epoch 29, Loss: 2.435510638093349\n",
            "Epoch 30, Loss: 2.394192647569585\n",
            "Epoch 31, Loss: 2.4031299224960234\n",
            "Epoch 32, Loss: 2.3760733375307224\n",
            "Epoch 33, Loss: 2.3647820865871716\n",
            "Epoch 34, Loss: 2.3372481471747104\n",
            "Epoch 35, Loss: 2.3279642313352107\n",
            "Epoch 36, Loss: 2.340563512870552\n",
            "Epoch 37, Loss: 2.364660640776335\n",
            "Epoch 38, Loss: 2.364074557822783\n",
            "Epoch 39, Loss: 2.423312226349695\n",
            "Epoch 40, Loss: 2.456844664317866\n",
            "Epoch 41, Loss: 2.5228196494768604\n",
            "Epoch 42, Loss: 2.558922750717339\n",
            "Epoch 43, Loss: 2.5254203105679975\n",
            "Epoch 44, Loss: 2.5100970555426403\n",
            "Epoch 45, Loss: 2.5381823202409115\n",
            "Epoch 46, Loss: 2.537699146663536\n",
            "Epoch 47, Loss: 2.5022355766281565\n",
            "Epoch 48, Loss: 2.417895973817222\n",
            "Epoch 49, Loss: 2.3730303000143937\n",
            "Epoch 50, Loss: 2.3356429012216076\n",
            "RMSE: 0.8797856880453606, MAE: 0.601460396336545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Try new dataset"
      ],
      "metadata": {
        "id": "MXvXGKyJYA27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()  # Clear GPU cache"
      ],
      "metadata": {
        "id": "WPCt9KciYC0b"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os.path as op\n",
        "import imp\n",
        "import numpy as np\n",
        "\n",
        "from zipfile import ZipFile\n",
        "try:\n",
        "    from urllib.request import urlretrieve\n",
        "except ImportError:  # Python 2 compat\n",
        "    from urllib import urlretrieve\n",
        "\n",
        "# this line need to be changed if not on colab:\n",
        "data_folder = '/content/'\n",
        "\n",
        "\n",
        "ML_1M_URL = \"https://files.grouplens.org/datasets/movielens/ml-32m.zip\"\n",
        "ML_1M_FILENAME = op.join(data_folder,ML_1M_URL.rsplit('/', 1)[1])\n",
        "ML_1M_FOLDER = op.join(data_folder,'ml-32m')"
      ],
      "metadata": {
        "id": "ksIpw1d7ZtGz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not op.exists(ML_1M_FILENAME):\n",
        "    print('Downloading %s to %s...' % (ML_1M_URL, ML_1M_FILENAME))\n",
        "    urlretrieve(ML_1M_URL, ML_1M_FILENAME)\n",
        "\n",
        "if not op.exists(ML_1M_FOLDER):\n",
        "    print('Extracting %s to %s...' % (ML_1M_FILENAME, ML_1M_FOLDER))\n",
        "    ZipFile(ML_1M_FILENAME).extractall(data_folder)"
      ],
      "metadata": {
        "id": "kTsS1BDcZxZ5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to the extracted dataset folder\n",
        "dataset_path = '/content/ml-32m'  # Adjust this path if needed\n",
        "\n",
        "# List all files in the folder\n",
        "files = os.listdir(dataset_path)\n",
        "print(\"Files in the dataset:\")\n",
        "for file in files:\n",
        "    print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzW_2HqyZxv3",
        "outputId": "b0915ddc-f0a1-4dfe-e997-63b4c8d6241a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the dataset:\n",
            "movies.csv\n",
            "checksums.txt\n",
            "README.txt\n",
            "tags.csv\n",
            "links.csv\n",
            "ratings.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "ratings = pd.read_csv('/content/ml-32m/ratings.csv')\n",
        "print(ratings.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eciubcvZzh8",
        "outputId": "43c6aafb-e00d-4f6c-e981-303c126c187d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating  timestamp\n",
            "0       1       17     4.0  944249077\n",
            "1       1       25     1.0  944250228\n",
            "2       1       29     2.0  943230976\n",
            "3       1       30     5.0  944249077\n",
            "4       1       32     5.0  943228858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv('/content/ml-32m/movies.csv')\n",
        "print(movies.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjiHde4NZ1gh",
        "outputId": "0e0dd0e3-878f-47e4-928c-9d40ab2d6d6b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1                   Adventure|Children|Fantasy  \n",
            "2                               Comedy|Romance  \n",
            "3                         Comedy|Drama|Romance  \n",
            "4                                       Comedy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure `movieId` in both datasets is of the same type\n",
        "ratings['movieId'] = ratings['movieId'].astype(int)\n",
        "movies['movieId'] = movies['movieId'].astype(int)\n",
        "\n",
        "# Merge the ratings and movies datasets on the common column 'movieId'\n",
        "all_ratings = ratings.merge(movies, on='movieId')\n",
        "\n",
        "# Preview the merged data\n",
        "print(all_ratings.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BOkWwnsZ3Rs",
        "outputId": "9c4a1167-8968-45be-cae3-3bf6bd626ea6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating  timestamp  \\\n",
            "0       1       17     4.0  944249077   \n",
            "1       1       25     1.0  944250228   \n",
            "2       1       29     2.0  943230976   \n",
            "3       1       30     5.0  944249077   \n",
            "4       1       32     5.0  943228858   \n",
            "\n",
            "                                               title  \\\n",
            "0                       Sense and Sensibility (1995)   \n",
            "1                           Leaving Las Vegas (1995)   \n",
            "2  City of Lost Children, The (Cité des enfants p...   \n",
            "3  Shanghai Triad (Yao a yao yao dao waipo qiao) ...   \n",
            "4          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n",
            "\n",
            "                                   genres  \n",
            "0                           Drama|Romance  \n",
            "1                           Drama|Romance  \n",
            "2  Adventure|Drama|Fantasy|Mystery|Sci-Fi  \n",
            "3                             Crime|Drama  \n",
            "4                 Mystery|Sci-Fi|Thriller  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the cutoff UNIX timestamp for 2024 June\n",
        "cutoff_timestamp_2022 = 1692302639\n",
        "\n",
        "# Filter the dataset for data after 2024\n",
        "new_data = all_ratings[all_ratings['timestamp'] >= cutoff_timestamp_2022].copy()\n",
        "\n",
        "# Count the number of records\n",
        "num_records_after_2021 = len(new_data)\n",
        "\n",
        "print(f\"Number of records after 2021: {num_records_after_2021}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4s9914oZ5cD",
        "outputId": "a3ee3bfd-7efa-4c73-819e-1b67d8f532a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records after 2021: 168882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create User-Item Interaction Matrix\n",
        "user_item_matrix = new_data.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "\n",
        "# 查看生成的交互矩阵\n",
        "print(\"User-Item Interaction Matrix:\")\n",
        "print(user_item_matrix.head())\n"
      ],
      "metadata": {
        "id": "N97zzl6ofZ7R",
        "outputId": "947293f0-0a4c-48e4-e70a-8b83dc881404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User-Item Interaction Matrix:\n",
            "movieId  1       2       3       4       5       6       7       9       \\\n",
            "userId                                                                    \n",
            "28          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "75          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "79          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "144         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "178         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "movieId  10      11      ...  292617  292619  292625  292627  292709  292731  \\\n",
            "userId                   ...                                                   \n",
            "28          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "75          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "79          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "144         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "178         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "movieId  292737  292753  292755  292757  \n",
            "userId                                   \n",
            "28          0.0     0.0     0.0     0.0  \n",
            "75          0.0     0.0     0.0     0.0  \n",
            "79          0.0     0.0     0.0     0.0  \n",
            "144         0.0     0.0     0.0     0.0  \n",
            "178         0.0     0.0     0.0     0.0  \n",
            "\n",
            "[5 rows x 17985 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train and test sets\n",
        "train_data, test_data = train_test_split(user_item_matrix, test_size=0.2, random_state=42)\n",
        "\n",
        "# 创建掩码 (Mask) 矩阵，用于标记已评分的数据\n",
        "train_mask = (train_data > 0).astype(float)\n",
        "test_mask = (test_data > 0).astype(float)\n",
        "\n",
        "print(f\"Train data shape: {train_data.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1dJpPTZgoTc",
        "outputId": "86535fc6-6bc2-4a53-f286-1bac6397be41"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (2936, 17985)\n",
            "Test data shape: (735, 17985)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "num_items = user_item_matrix.shape[1]\n",
        "hidden_neurons = 500\n",
        "learning_rate = 0.001\n",
        "lambda_value = 0.1\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "# Instantiate and train the model\n",
        "autorec = AutoRec(num_items, hidden_neurons, learning_rate, lambda_value)\n",
        "autorec.train(train_data.values, train_mask.values, epochs, batch_size)\n",
        "\n",
        "# Predict on test set\n",
        "test_predictions = autorec.predict(test_data.values)\n",
        "\n",
        "# Evaluate the model\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "true_ratings = test_data.values[test_mask.values > 0]\n",
        "predicted_ratings = test_predictions[test_mask.values > 0]\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
        "mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFeJf2m1grex",
        "outputId": "b50a87a8-44e9-4e8a-91e7-70866e536497"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 241.02028362887432\n",
            "Epoch 2, Loss: 65.52700755771565\n",
            "Epoch 3, Loss: 45.44964566347709\n",
            "Epoch 4, Loss: 39.9240370914137\n",
            "Epoch 5, Loss: 36.68734865942183\n",
            "Epoch 6, Loss: 34.12954961376554\n",
            "Epoch 7, Loss: 31.793474743086897\n",
            "Epoch 8, Loss: 29.76262554615655\n",
            "Epoch 9, Loss: 27.96130396039999\n",
            "Epoch 10, Loss: 26.32609300327561\n",
            "Epoch 11, Loss: 24.841238120596156\n",
            "Epoch 12, Loss: 23.432187363627172\n",
            "Epoch 13, Loss: 22.145386448997893\n",
            "Epoch 14, Loss: 20.91818224831563\n",
            "Epoch 15, Loss: 19.798847084149354\n",
            "Epoch 16, Loss: 18.781331366349306\n",
            "Epoch 17, Loss: 17.85716126985056\n",
            "Epoch 18, Loss: 16.958420465038\n",
            "Epoch 19, Loss: 16.100006186669788\n",
            "Epoch 20, Loss: 15.303344310791681\n",
            "Epoch 21, Loss: 14.533219028233832\n",
            "Epoch 22, Loss: 13.706840411194014\n",
            "Epoch 23, Loss: 13.059992236727265\n",
            "Epoch 24, Loss: 12.485667257282975\n",
            "Epoch 25, Loss: 11.860256621233448\n",
            "Epoch 26, Loss: 11.357776693817055\n",
            "Epoch 27, Loss: 11.110774962713673\n",
            "Epoch 28, Loss: 10.581285377939\n",
            "Epoch 29, Loss: 10.642947558161348\n",
            "Epoch 30, Loss: 10.748198132424005\n",
            "Epoch 31, Loss: 11.04387018271298\n",
            "Epoch 32, Loss: 11.632044820759537\n",
            "Epoch 33, Loss: 12.66276076314235\n",
            "Epoch 34, Loss: 13.64709930004151\n",
            "Epoch 35, Loss: 15.176949649155953\n",
            "Epoch 36, Loss: 17.41197146381929\n",
            "Epoch 37, Loss: 18.804736685687903\n",
            "Epoch 38, Loss: 18.419848408296257\n",
            "Epoch 39, Loss: 16.750874989688885\n",
            "Epoch 40, Loss: 14.852611032428793\n",
            "Epoch 41, Loss: 12.518269884488888\n",
            "Epoch 42, Loss: 10.154607206339408\n",
            "Epoch 43, Loss: 8.20241234802745\n",
            "Epoch 44, Loss: 7.039623312469399\n",
            "Epoch 45, Loss: 6.374328966686447\n",
            "Epoch 46, Loss: 5.978571837214748\n",
            "Epoch 47, Loss: 5.65369695928506\n",
            "Epoch 48, Loss: 5.487251655932019\n",
            "Epoch 49, Loss: 5.355247747021085\n",
            "Epoch 50, Loss: 5.252923970651237\n",
            "RMSE: 1.1806, MAE: 0.8596\n"
          ]
        }
      ]
    }
  ]
}